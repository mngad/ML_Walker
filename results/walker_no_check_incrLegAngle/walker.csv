Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
4992000,1.1004679,56.285714285714285,7.795528,1.9299026557377406,1.9299026557377406,6.4992666,0.022222295,0.00029700575,0.19900194,0.0009901191,1.0
5004000,1.1001834,134.66666666666666,13.282974,16.043237686157227,16.043237686157227,16.797792,0.01968638,0.00029700095,0.19900031,0.0009901031,1.0
5016000,1.1000543,246.66666666666666,24.982244,62.03690322240194,62.03690322240194,54.63679,0.018117309,0.00029699362,0.19899786,0.0009900789,1.0
5028000,1.0984458,453.0,39.21169,130.1639296229069,130.1639296229069,103.22205,0.018874373,0.00029698617,0.1989954,0.0009900545,1.0
5040000,1.0972573,432.8072289156627,52.709,213.2080989005044,213.2080989005044,104.58572,0.018359726,0.00029697936,0.19899313,0.0009900318,1.0
