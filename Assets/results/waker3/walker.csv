Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
348000,1.4325845,43.94444444444444,2.2757425,0.8833333518770006,0.8833333518770006,1.0
360000,1.432329,137.27272727272728,2.5441177,3.027272804216905,3.027272804216905,1.0
372000,1.4329951,171.45454545454547,2.3135188,4.22727279771458,4.22727279771458,1.0
384000,1.4334198,307.75,2.523822,8.262500081211329,8.262500081211329,1.0
396000,1.4337411,347.0,2.5570407,10.086666744947433,10.086666744947433,1.0
408000,1.4344548,453.45454545454544,2.5203087,13.030000069737435,13.030000069737435,1.0
420000,1.4357384,591.5,2.6339,14.364285818168096,14.364285818168096,1.0
432000,1.4368325,577.1666666666666,2.5437284,15.660000084340572,15.660000084340572,1.0
444000,1.4380367,657.4666666666667,2.4759336,19.30625005438924,19.30625005438924,1.0
456000,1.4386955,753.1538461538462,2.5846431,20.020000118017197,20.020000118017197,1.0
468000,1.4382095,663.0,2.6279776,19.530769281662426,19.530769281662426,1.0
480000,1.438235,644.3,2.6828527,13.785714370863777,13.785714370863777,1.0
492000,1.4378743,903.6153846153846,2.6445205,26.521428614854813,26.521428614854813,1.0
504000,1.4378586,758.1363636363636,2.5118594,22.400000036778774,22.400000036778774,1.0
516000,1.4391512,992.3333333333334,2.4485476,28.383333360155422,28.383333360155422,1.0
528000,1.4400172,765.5333333333333,2.642686,17.20769233887012,17.20769233887012,1.0
